{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_with_MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP85/n1RrzOSQMTtavvgYuR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lagamaite/Colab-Notebooks/blob/master/GAN_with_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC_2NeBq6s6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g5RstiiB8V-z",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow==2.0.0-rc1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "avMNdOnx1AcF",
        "colab": {}
      },
      "source": [
        "# To generate GIFs\n",
        "!pip install -q imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0O1_9eu60jF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woqodfQK7IqU",
        "colab_type": "code",
        "outputId": "22d1c2d0-a976-40da-da38-4f6b7e694bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZyhT0q997cO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To generate GIFs\n",
        "!pip install -q imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MWDmAzh-AMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvB8_OCu-Pax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFC2ghIdiZYE",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4PIDhoDLbsZ",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-yKCCQOoJ7cn",
        "colab": {}
      },
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6bpTcDqoLWjY",
        "colab": {}
      },
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gl7jcC7TdPTG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ec1efe73-45f9-4f2e-82e3-b78d396ce57a"
      },
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2712460c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAYL0lEQVR4nO2deZCU5bXGnzMjyCqyOywCyuIu4LiE\nxTJRDIKRxJQmJGWgkrqYqizGpFI3lVtEysofitctxY0VFJXc5BqNSiAlRsaBOJCwOOKA7AhBBAdG\nlrAoIwOc+8c0Ceq8zzvpHrq78j6/qqnu6WdOf29/3c983X2+c465O4QQ//6UFHoBQoj8ILMLkQgy\nuxCJILMLkQgyuxCJcEY+N9axY0fv2rVrUI9lBpheWlqa9bqas+3jx48HtZIS/j/TzKh+4sQJqudC\nq1atqN7Q0ED12GPLhWPHjuW07dhjYxw5coTqsddT7DmN6eyxxx430/fu3YvDhw83ufGczG5mYwE8\nCqAUwBPufh/7+65du2Lq1KlB/aOPPqLbYzuoc+fONDYXMwPA/v37g1qHDh1obOyF8+GHH1I99sJh\n9OjRg+p1dXVUb9euHdVj+5X9I9u3b19O2+7ZsyfVGWvXrqV6p06dqB57Ttu0aUN1tt87duxIY1u3\nbh3U7r///qCW9b9tMysF8D8AbgJwEYCJZnZRtvcnhDi95PIe7SoAb7v7Vnc/CuB3ACa0zLKEEC1N\nLmbvDeDdU37fkbntY5jZFDOrNrPqQ4cO5bA5IUQunPZv4919pruXu3t57LOIEOL0kYvZdwLoe8rv\nfTK3CSGKkFzM/jqAQWY2wMxaA/gqgHktsywhREuTderN3Y+Z2XcBvILG1NuT7s7zGeCpmFgKqnv3\n7kGN5e8BYOPGjVSvr6+nOkv7lZeX09i9e/dSPZbzjeXCzznnnKC2Zs0aGtuvXz+qn848+549e6ge\ne05jacOBAwcGtQMHDtDYYcOGZX3fALBlyxaqv/vuu0FtwIABNJal3s44I2zpnPLs7j4fwPxc7kMI\nkR90uqwQiSCzC5EIMrsQiSCzC5EIMrsQiSCzC5EIea1nd3eaZ4+VFbKywVjJYqwkccOGDVRnufRY\njj5Wr85yowAwZMgQqi9fvjyoxWrGV6xYQfXBgwdTffjw4VR/++23g9rll19OY1k+GYjn2f/yl78E\ntT59+tDYWB3HokWLqH7uuedS/ayzzgpqsdJetjb2WtORXYhEkNmFSASZXYhEkNmFSASZXYhEkNmF\nSIS8pt6A3NomsxRVrIy0rKyM6mPGjMk6vqqqisZ+8MEHVI+loBYsWEB1tl/OP/98Ghvrqjt69Giq\nz5vHWxiw7bNOwwDwyCOPUD1WGjxixIigVllZSWP79u1L9d69P9WB7WOwtB/AU3OxtN2yZcuCGm15\nTu9VCPFvg8wuRCLI7EIkgswuRCLI7EIkgswuRCLI7EIkgsWmcLYkgwYN8kcffTSor1y5ksZ36dIl\nqMWmzcRy3bES2LZt2wa1s88+m8bGcrJLly6leqzUk+2XWNlwdXU11VkpJhCfpMrKb0eOHEljY62m\nY+2c2XMeK2GNnZfx2muvUf3o0aNUZyW2rM00wNtgP/vss9i9e3eTY391ZBciEWR2IRJBZhciEWR2\nIRJBZhciEWR2IRJBZhciEfJez27WZAoQANCtWzcay0Y2x+rkY+Ogt2/fTnVW1x3L2cb0OXPmUP3e\ne++lOsu7xkYuv/HGG1RnNeEAsHXrVqqztS1evJjGfv/736f6PffcQ/ULL7wwqL333ns0dvz48VSP\nteiO7ff9+/cHtVh/A1ZrX1FREdRyMruZbQNwCMBxAMfcnQ8qF0IUjJY4sn/W3fmpTkKIgqPP7EIk\nQq5mdwALzOwNM5vS1B+Y2RQzqzaz6oMHD+a4OSFEtuT6Nn6Uu+80sx4AKsxsg7t/rPuiu88EMBNo\nLITJcXtCiCzJ6cju7jszl3UA5gC4qiUWJYRoebI2u5m1N7OOJ68DuBHAmpZamBCiZcnlbXxPAHMy\nefMzAPyfu/+JBZw4cYLmu2Oji1luMpZn79q1K9Vj/dPZtmtqamhsbKTzhAkTqM5qwgF+fkKsHn3o\n0KFUj+XZ2X4B+Npiddvbtm2jeqy3e6tWrYJa7NyHWJ48NvK5ffv2VGffX7Ex1wB/XA0NDUEta7O7\n+1YAPPsvhCgalHoTIhFkdiESQWYXIhFkdiESQWYXIhHyWuJaUlKCM888M6hffPHFNJ6VY+7atYvG\n7ty5k+r79u2jeq9evYJamzZtaGwsPTVo0CCqxx4bS+399a9/pbGxVtC5phVZS+U333yTxo4bN47q\nsfiJEycGtdjzHSthjY0Ij41sPu+884JabG2sHJul9HRkFyIRZHYhEkFmFyIRZHYhEkFmFyIRZHYh\nEkFmFyIR8p5nZ6OVH374YRr/hS98IajFctkDBgyg+iuvvEJ1Vn579dVX09jrr7+e6n/4wx+ozlpo\nA7yM9JZbbqGxv/nNb6geK/2NnSPARh/HSnfXr19P9enTp1N9wYIFQa1du3Y09uWXX6Y6a4kOxMd4\nX3bZZUEtVvrLzlWZP39+UNORXYhEkNmFSASZXYhEkNmFSASZXYhEkNmFSASZXYhEyGuevb6+HuvW\nrQvqsdrq0tLSoNa2bVsa686H0cS2fcMNNwS1119/ncZWVVVRffXq1VSfOnUq1f/0p3AH7z//+c80\ntrKykuo333wz1WMtk9n5Czt27KCxsbHKL730EtXXrl0b1GI9Au6++26qb968mers/AIAWLhwYVCL\nnbvQuXPnoMY8oiO7EIkgswuRCDK7EIkgswuRCDK7EIkgswuRCDK7EImQ1zy7mdG68Msv50NhWT/t\nSy+9lMa2bt2a6rE8PesjPnr0aBpbW1tL9dio6o0bN1K9d+/eQS1Waz9w4ECq7969m+osXwzwcdSx\nHH1sv8Zy5aw3+7Jly2hsrIdAbL8tXrw46/vv168fjV2zZk1Q++ijj4Ja9MhuZk+aWZ2ZrTnlti5m\nVmFmmzOX4Sy/EKIoaM7b+KcBjP3EbT8BUOnugwBUZn4XQhQxUbO7exWAT75/ngBgdub6bABfbOF1\nCSFamGy/oOvp7ic/iO4CEDyx3MymmFm1mVUfOnQoy80JIXIl52/jvbHCJFhl4u4z3b3c3ctZs0kh\nxOklW7PvNrMyAMhc1rXckoQQp4NszT4PwKTM9UkA5rbMcoQQp4tont3MngFwHYBuZrYDwD0A7gPw\nnJl9C8A7AG5vzsZKSkpoPjuWK2c9zFmPcCBeG81ysgAwePDgoBary2Z11QBwxRVXUD22X2bMmBHU\nYo+b1ekD8Tx7bO0dOnQIamx+OgBUVFRQffbs2VRn+y3Wv2Dbtm1U37p1K9Xff/99qrO68xtvvJHG\nslp61s8+anZ3Dz0jfPKBEKKo0OmyQiSCzC5EIsjsQiSCzC5EIsjsQiRC3ktcW7VqFdRXrlxJ41ls\nbLzvlVdeSfWhQ4dSnbWL7tKlC4297rrrqP7QQw9R/bbbbqN6p06dgtqQIUNobE1NDdV79OhB9Vjb\n4/r6+qAWa6H9xBNPUH3SpElULykJH8t27txJY2MjwFnJMwDceuutVJ81a1ZQ+/3vf09jWYnrkSNH\ngpqO7EIkgswuRCLI7EIkgswuRCLI7EIkgswuRCLI7EIkQl7z7MeOHcPevXuDOhvnDPD2vWPGjKGx\n/fv3p3ostzl27Cd7bv6TuXN5OX8sD9+uXTuqx/L0rByTnZsAAI888gjVH3zwQarHWlWzkdHPP/88\njf3GN75B9fHjx1N9zpw5QS1WujtlyhSqv/jii1R/7rnnqL59+/agFuvodPvt4YryJUuWBDUd2YVI\nBJldiESQ2YVIBJldiESQ2YVIBJldiESQ2YVIhLzm2UtKSmgO8eyzz6bxJ06cCGp1dXxOBRtlCwAf\nfPAB1RctWhTU7r33Xho7bdo0ql988cVUX7p0KdVZLX4uY40BoKGhgeoHDhygOhv5FXtOYqxatYrq\nbMR3rBU0e74B4KabbqJ6bMw2ay/O2kwD/LwNFqsjuxCJILMLkQgyuxCJILMLkQgyuxCJILMLkQgy\nuxCJkNc8u7vTftujRo2i8SxvykZBA/ERurFcNzsH4Omnn6axvXr1ojrrrQ4AZWVlVGd5+AsuuIDG\n/uIXv6B6LOf7wAMPUJ31tL/rrrtoLHu+gXjN+Oc///mgxvoqAEBVVRXVY/Xwsd4MrIcB63cPAC+8\n8EJQY/3uo0d2M3vSzOrMbM0pt00zs51mVpP5GRe7HyFEYWnO2/inATTVpuVhdx+a+ZnfsssSQrQ0\nUbO7exUA/n5KCFH05PIF3XfNbHXmbX7n0B+Z2RQzqzaz6sOHD+ewOSFELmRr9scAnA9gKIBaAMGu\nhO4+093L3b28Q4cOWW5OCJErWZnd3Xe7+3F3PwHgcQBXteyyhBAtTVZmN7NTc0FfAhCeISuEKAqi\neXYzewbAdQC6mdkOAPcAuM7MhgJwANsA3NmcjZWUlNA+5rFcuLuzddLY2tpaqsdy2ez+Y7Gx+eqx\n/ulnnMGfpvbt2we12Een+fN5IoXlyQHgwgsvpDqrtY/1Xr/yyiup/pWvfIXqrP9BLIf/9a9/nerL\nli2jOsvxA/w5i72eWB8A5pGo2d19YhM3hyfJCyGKEp0uK0QiyOxCJILMLkQiyOxCJILMLkQiFFWJ\na6y9LytDZWkWIJ7W27x5M9XZ6OKpU6fS2EsuuYTqK1asoHqsxfYPf/jDoMbGFgPArFk8sfLyyy9T\nfeHChVR/7LHHglqsjDQ2ZpuNPQaAPXv2ZB17yy23UD32emLbBoDJkycHtfvuu4/GstHlZ555ZlDT\nkV2IRJDZhUgEmV2IRJDZhUgEmV2IRJDZhUgEmV2IRMhrnv3EiRM4evRoUG/dunU0PlvGjm2qZ+Y/\nefXVV6nORux+7Wtfo7GxtsUsNwrEx0nPnTs3qMVabI8cOZLqsZbJEyc2VRT5T9hIaFb+CsTHIq9c\nuZLqrIy0pqaGxj777LNU79w52IkNQHy///KXvwxqsXJtVvLM2lDryC5EIsjsQiSCzC5EIsjsQiSC\nzC5EIsjsQiSCzC5EIuQ1z15aWoqzzjorqLMxtgBw6aWXBrVYS+Tjx49T/ciRI1RnNcQVFRU09uqr\nr6b66NGjqc7yxQAfD7xjxw4aG6u1HzFiBNVjufDhw4cHtWHDhtHYc889l+p//OMfqT5+/PisY2+4\n4QaqP/PMM1Tv1q0b1dlrvWfPnjR248aNQY2di6IjuxCJILMLkQgyuxCJILMLkQgyuxCJILMLkQgy\nuxCJkPe+8Wzc7KpVq2g8q/uO5cljPcgvuOACqrM+4bF69Fg9+1NPPUX1L3/5y1Rv06ZNUOvRoweN\n/fvf/051lsMHgG9/+9tUZ8/pjBkzaCzrfQAA11xzDdVZzfq4ceNo7P79+6nep08fqsd6Mxw6dCio\nvfnmm1nHNjQ0BLXokd3M+prZIjNbZ2ZrzeyuzO1dzKzCzDZnLnk1vxCioDTnbfwxAD9y94sAXAPg\nO2Z2EYCfAKh090EAKjO/CyGKlKjZ3b3W3Vdmrh8CsB5AbwATAMzO/NlsAF88XYsUQuTOv/QFnZn1\nBzAMwHIAPd29NiPtAtDkCb1mNsXMqs2smn3WEEKcXpptdjPrAOAFAD9w94Onau7uALypOHef6e7l\n7l7esWPHnBYrhMieZpndzFqh0ei/dfcXMzfvNrOyjF4GoO70LFEI0RJEU2/W2Nd2FoD17v7QKdI8\nAJMA3Je5DPczztDQ0ID33nsvqMdKGrt37x7UamtrgxoAfPjhh1TftGkT1X/84x8HtV27dtHYWBom\nNt431kKbjZvu0qULjY2NLr7sssuoHistZmu/9dZbaWysRfcDDzxAddbG+v7776exsdRcLE3Mtg3w\n1B4r5Qb4a52lgZuTZx8J4A4Ab5nZycTlT9Fo8ufM7FsA3gFwezPuSwhRIKJmd/clAEJd669v2eUI\nIU4XOl1WiESQ2YVIBJldiESQ2YVIBJldiETIeytplveNnWHHWuheccUVNHbAgAFUj40mZiWu9fX1\nNDZWRhpb24YNG7KOP3z4MI2N5ZMff/xxqo8aNYrqW7duDWrs+QTieXRWzgkACxcuDGq33XYbjWWl\n2EC8/JaNVQaAxYsXB7XYiO6bb745qLEW1TqyC5EIMrsQiSCzC5EIMrsQiSCzC5EIMrsQiSCzC5EI\nec2zA7y+efDgwTSW5SZjefK//e1vVI+1kmbnALAx1ADQqlUrqk+ePJnqsZxup06dglosR19ZWUn1\nkSNHUn3fvn1UZ4891t57yJAhVI/1MGA142PHjqWxrD03AHTo0IHqsfbh1157bVDr1asXjX3++eeD\nGnvMOrILkQgyuxCJILMLkQgyuxCJILMLkQgyuxCJILMLkQjWOMwlP/Tv399/9rOfBfUdO3bQ+Fxy\n9DGWL19O9Z49m5xuBQAoLy+nscePH6d6rOY8Fl9XF57P0dj2P0zXrl2pXlZWRvVYf3TWByB2DkCs\nrjvWB2DFihVBLZZHj41kbt++PdVjvf6XLFkS1GLnVbAeBN/73vewadOmJp90HdmFSASZXYhEkNmF\nSASZXYhEkNmFSASZXYhEkNmFSITmzGfvC+DXAHoCcAAz3f1RM5sG4D8AnEyk/tTd6bDu0tJSmp+M\n5T7p7OlIn+7YfcfyzayevaqqisbGap9j8XfccQfVS0rC/7PXrVtHY2PnNtx9991U37JlC9VZLj02\n4/wzn/kM1Q8cOEB1Nree5bkBYMaMGVSPPW6W4weAESNGBLXS0lIaO2jQoKCW63z2YwB+5O4rzawj\ngDfMrCKjPezu/92M+xBCFJjmzGevBVCbuX7IzNYD6H26FyaEaFn+pc/sZtYfwDAAJ88t/a6ZrTaz\nJ82scyBmiplVm1n1wYMHc1qsECJ7mm12M+sA4AUAP3D3gwAeA3A+gKFoPPI/2FScu89093J3L4/1\nahNCnD6aZXYza4VGo//W3V8EAHff7e7H3f0EgMcBXHX6limEyJWo2a2xbGoWgPXu/tApt59aDvUl\nAGtafnlCiJaiOd/GjwRwB4C3zKwmc9tPAUw0s6FoTMdtA3Bn7I4aGhpoyWNNTU1QA4BzzjknqPXo\n0YPGbtu2jept27alOitjXbp0KY2NtZJmZb8AsGfPHqqztOHAgQNzuu9YCimWJmLbj5WBvvPOO1SP\nxbPXy/Tp02kse50CwGuvvUZ11ioaALp37x7Ujhw5QmOZT1hsc76NXwKgqfpYmlMXQhQXOoNOiESQ\n2YVIBJldiESQ2YVIBJldiESQ2YVIhLyObC4pKaH5bFb2dzI+xKJFi2hs7968dieWZ6+vrw9qsVLL\nWKnm9u3bqR5b21NPPRXUPve5z9HYWJtqlqsG4vlopn/zm9+ksT//+c+pvmYNP49r+PDhQe2ll16i\nsXfeyU8biZ1bETvvg5Uex8ZJ/+pXvwpq7LWoI7sQiSCzC5EIMrsQiSCzC5EIMrsQiSCzC5EIMrsQ\niZDXkc1m9j6AU4uUuwHgBdWFo1jXVqzrArS2bGnJtfVz9yaL5fNq9k9t3Kza3flw8wJRrGsr1nUB\nWlu25GttehsvRCLI7EIkQqHNPrPA22cU69qKdV2A1pYteVlbQT+zCyHyR6GP7EKIPCGzC5EIBTG7\nmY01s41m9raZ/aQQawhhZtvM7C0zqzGz6gKv5UkzqzOzNafc1sXMKsxsc+ayyRl7BVrbNDPbmdl3\nNWY2rkBr62tmi8xsnZmtNbO7MrcXdN+RdeVlv+X9M7uZlQLYBGAMgB0AXgcw0d35IPE8YWbbAJS7\ne8FPwDCzawEcBvBrd78kc9t0APvc/b7MP8rO7v6fRbK2aQAOF3qMd2ZaUdmpY8YBfBHAZBRw35F1\n3Y487LdCHNmvAvC2u29196MAfgdgQgHWUfS4exWAfZ+4eQKA2Znrs9H4Ysk7gbUVBe5e6+4rM9cP\nATg5Zryg+46sKy8Uwuy9Abx7yu87UFzz3h3AAjN7w8ymFHoxTdDT3Wsz13cB6FnIxTRBdIx3PvnE\nmPGi2XfZjD/PFX1B92lGuftwADcB+E7m7WpR4o2fwYopd9qsMd75ookx4/+gkPsu2/HnuVIIs+8E\n0PeU3/tkbisK3H1n5rIOwBwU3yjq3Scn6GYu6wq8nn9QTGO8mxozjiLYd4Ucf14Is78OYJCZDTCz\n1gC+CmBeAdbxKcysfeaLE5hZewA3ovhGUc8DMClzfRKAuQVcy8coljHeoTHjKPC+K/j4c3fP+w+A\ncWj8Rn4LgP8qxBoC6zoPwKrMz9pCrw3AM2h8W9eAxu82vgWgK4BKAJsBvAqgSxGt7X8BvAVgNRqN\nVVagtY1C41v01QBqMj/jCr3vyLryst90uqwQiaAv6IRIBJldiESQ2YVIBJldiESQ2YVIBJldiESQ\n2YVIhP8H7rRRVNBPNk8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dw2tPLmk2pEP",
        "colab": {}
      },
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDkA05NE6QMs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c66c687e-ce30-4e94-b210-5a2e0ef018c0"
      },
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-0.00126975]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "psQfmXxYKU3X",
        "colab": {}
      },
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wkMNfBWlT-PV",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "90BIcCKcDMxz",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iWCn_PVdEJZ7",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CA1w-7s2POEy",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3t5ibNo05jCB",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2M7LmLtGEMQJ",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmdVsmvhPxyy",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ly3UN0SLLY2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "fb842315-a5f8-4913-db4c-cb2c57a83124"
      },
      "source": [
        "train(train_dataset, epochs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d0e3ab41d250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOYeMRI1zqmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WfO5wCdclHGL",
        "colab": {}
      },
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5x3q9_Oe5q0A",
        "colab": {}
      },
      "source": [
        "display_image(EPOCHS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IGKQgENQ8lEI",
        "colab": {}
      },
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import IPython\n",
        "if IPython.version_info > (6,2,0,''):\n",
        "  display.Image(filename=anim_file)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uV0yiKpzNP1b",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(anim_file)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}